# 项目相关的常见问题
## DB和ES如何数据同步？
1.全量和基于日期的增量同步：基于定时任务，开发同步接口，从数据库里查询符合条件的数据，批量写入es。
2.实时同步：采用 CDC+Kafka 的架构，CDC 工具读取 mysql 的 binlog，解析成结构化数据，发送到消息队列，消费者从队列读取数据并同步到ES
### 其他方案
双写，在应用层实现双写，写入数据库的同时更新Elastic Search，缺点是对代码的入侵性强，且难以保证事务一致性。
### canal的原理
canal可以模拟MySQL的从库协议，作为MySQL的一个从库连接到主库，读取binlog日志，并将其解析成结构化的数据，发送到消息队列或者其他存储系统中，供下游系统消费。

## 你是怎么做sql性能优化的？
对于sql性能优化，主要从下面几个方面入手
### 1.索引优化
- 合理创建索引：条件列创建索引，优先使用联合索引，并遵循最左前缀原则，避免在索引列上使用函数
- 覆盖索引：索引的列包含了所有要返回的列，查询仅通过索引就能获取需要的数据，避免回表
- 避免冗余索引：定期检查并删除未使用的索引
### 2.SQL语句优化
- 避免 SELECT *
- 确保 JOIN 字段有索引，join的两个表，小表在左边，小表驱动大表
- 避免隐式类型转换
### 3.数据库设计优化
- 适当冗余可减少 JOIN
- 大表按时间/范围分区，水平分表
### 4.缓存策略
- 应用层缓存：使用 Redis 缓存热点数据

## 讲一个你们的项目离比较复杂的业务流程
好的，那我简单说一下我们对文件的处理流程吧。
首先我们会提供api给上游系统或者用户上传文件，dmc-api负责接受请求，做数据校验，然后调用dmc-workflow，dmc-workflow接收数据，把文件通过接口调用的方式传给dmc-s3-service，dmc-s3-service负责把文件存储到我们自建的s3存储集群中，存储成功后会返回文件的访问地址给dmc-workflow，然后dmc-workflow发送kafka消息通知dmc-ocr，进行文件ocr识别，dmc-ocr处理完成，发送kafka消息通知