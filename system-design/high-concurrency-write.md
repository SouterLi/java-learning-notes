# 实战场景题 - 高并发

## 高并发秒杀中的超卖于数据一致性挑战
### 场景
现有电商秒杀活动，预估峰值QPS 50K+。当前方案：Redis缓存库存，预扣减成功后异步写MQ通知下游扣减数据库库存。线上发现存在超卖（实际库存不足但下单成功）且偶发用户支付成功但库存未扣。请分析原因，并提出优化方案。
### 可能原因分析
- 超卖： 主要原因在预扣减环节：
  - Redis预扣减成功但未同步到数据库：可能由于网络问题、Redis主从切换等导致同步失败。
  - 多节点并发请求未能正确串行化处理，导致库存被多次预扣减。
  - Redis数据不一致：如Redis宕机后恢复时数据未及时同步，导致库存信息错误。
- 支付成功库存未扣： 可能原因包括：
  - 消息队列消息丢失：MQ未持久化或消费者处理失败未重试，导致库存扣减消息未被处理。
  - 消费端幂等性不足：重复消费同一消息导致库存扣减逻辑异常。
  - 数据库事务未能正确提交：如订单创建成功但库存扣减事务失败未回滚。
### 优化方案
#### 1. 强化预扣减逻辑
- 使用Lua脚本在Redis中实现原子操作，确保预扣减和库存检查在同一操作中完成，避免多节点并发问题。
- 引入分布式锁（如RedLock）确保同一商品的库存操作串行化处理。
#### 2. 确保消息队列的可靠性
- 使用持久化的消息队列（如Kafka）确保消息不丢失。
- 实现消息的幂等消费，确保重复消费不会导致库存异常。
- 引入消息确认机制，确保消息被成功处理后才从队列中移除。
#### 3. 数据库事务优化
- 使用分布式事务（如Seata）确保订单创建和库存扣减的一致性。
- 在库存扣减时，使用乐观锁（版本号）或悲观锁（SELECT FOR UPDATE）确保库存数据的正确性。

## 高并发数据库插入与展示
场景  
高并发插入数据库，1秒3000条，页面上每秒刷新一次，只展示前10条
详细设计：
#### 一、写入流程
1. 数据接收：通过API接收数据，将数据推送到消息队列（如Kafka、RabbitMQ）中。这样可以将突发的写入流量缓冲，避免直接冲击数据库。
2. 消费队列：使用多个消费者从队列中批量取出数据（例如每100条或每50毫秒批量一次），然后批量插入数据库。
- 批量插入可以大大减少数据库的写入次数，提高吞吐量。
- 同时，在插入数据库后，将这批数据同时写入缓存（Redis）的一个有序集合（Sorted Set）中，按时间戳排序。
#### 二、读取流程
1. 页面请求最新10条数据时，直接从Redis的有序集合中获取分数（时间戳）最大的10条。
2. 这样避免了每次读取都查询数据库，减轻数据库压力。
#### 三、缓存设计
- 使用Redis的Sorted Set，以时间戳（或自增ID）作为分数（score），数据内容作为成员（member）。
- 每次新数据写入时，将其添加到Sorted Set中，并移除超出范围的数据（比如只保留最新的1000条，避免Sorted Set无限增长）。
- 获取最新10条：使用`ZREVRANGE`命令（从大到小排序）取前10个。
#### 四、数据库设计
- 数据库表设计：包含自增ID、数据内容、创建时间等字段。
- 索引：在创建时间字段上建立索引，以便于查询（虽然我们主要从缓存读，但有时可能需要查询历史数据）。
- 注意：由于写入量很大，索引不宜过多，否则会影响写入性能。主键索引是必须的，时间字段索引用于可能的查询。
#### 五、前端设计
- 每秒刷新一次：可以使用定时器（setInterval）每秒请求一次数据。
- 但更好的方式是使用WebSocket，当服务端有新数据时主动推送给前端，这样前端可以实时更新而不需要定时轮询。

## 红包系统
### 挑战：
- 瞬时高并发，系统压力
- 一致性控制，防止超抢红包
- 幂等性控制，同一个人不能抢多个
- 红包随机生成控制