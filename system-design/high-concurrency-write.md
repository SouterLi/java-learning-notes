# 高并发数据库插入与展示
场景  
高并发插入数据库，1秒3000条，页面上每秒刷新一次，只展示前10条
详细设计：
#### 一、写入流程
1. 数据接收：通过API接收数据，将数据推送到消息队列（如Kafka、RabbitMQ）中。这样可以将突发的写入流量缓冲，避免直接冲击数据库。
2. 消费队列：使用多个消费者从队列中批量取出数据（例如每100条或每50毫秒批量一次），然后批量插入数据库。
- 批量插入可以大大减少数据库的写入次数，提高吞吐量。
- 同时，在插入数据库后，将这批数据同时写入缓存（Redis）的一个有序集合（Sorted Set）中，按时间戳排序。
#### 二、读取流程
1. 页面请求最新10条数据时，直接从Redis的有序集合中获取分数（时间戳）最大的10条。
2. 这样避免了每次读取都查询数据库，减轻数据库压力。
#### 三、缓存设计
- 使用Redis的Sorted Set，以时间戳（或自增ID）作为分数（score），数据内容作为成员（member）。
- 每次新数据写入时，将其添加到Sorted Set中，并移除超出范围的数据（比如只保留最新的1000条，避免Sorted Set无限增长）。
- 获取最新10条：使用`ZREVRANGE`命令（从大到小排序）取前10个。
#### 四、数据库设计
- 数据库表设计：包含自增ID、数据内容、创建时间等字段。
- 索引：在创建时间字段上建立索引，以便于查询（虽然我们主要从缓存读，但有时可能需要查询历史数据）。
- 注意：由于写入量很大，索引不宜过多，否则会影响写入性能。主键索引是必须的，时间字段索引用于可能的查询。
#### 五、前端设计
- 每秒刷新一次：可以使用定时器（setInterval）每秒请求一次数据。
- 但更好的方式是使用WebSocket，当服务端有新数据时主动推送给前端，这样前端可以实时更新而不需要定时轮询。